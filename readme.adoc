= EDA Compute
:toc:
:source-highlighter: highlightjs
:icons: font
:javaPath: src/main/java/org/veupathdb/service/eda/compute
:kotlinPath: src/main/kotlin/org/veupathdb/service/eda/compute
// Github specifics
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
Elizabeth Paige Harper <epharper@upenn.edu>
v1.0.0


== Plugin Development

=== Adding a Plugin

TODO!!

link:src/main/java/org/veupathdb/service/eda/compute/plugins/example[Example Plugin]

. Add the plugin RAML to new or existing files in the link:schema/url/computes[plugins schema directory]. +
  (See the link:schema/url/computes/example.raml[example plugin schema])
. Add the new plugin endpoint to the project's link:api.raml[API Definition RAML].
. Run the command `make raml-gen-code` to generate the new Java source code for the plugin being added.
. Add a new package for your plugin in the link:{javaPath}/plugins/[plugins package] +
  (See the link:{javaPath}/plugins/example[example plugin package])
. Follow the steps outlined in the link:{javaPath}/plugins[plugins package readme].
. Add an endpoint for your new plugin in the link:{javaPath}/controller/ComputeController.java[Plugin Controller]

==== Plugin RAML

TODO

==== API RAML

Plugins MUST add at least one endpoint to the link:api.raml[`api.raml`] file.  This endpoint must accept a POST request
with a request body that extends the `ComputeRequestBase` type defined in the
link:schema/url/computes.raml[`computes.raml`] RAML library file.  This endpoint MUST specify, at minimum, a `200`
status response returning the RAML type `lib.JobResponse` in the media type `application/json`.

Additionally, each plugin execution endpoint definition MUST contain a sub-endpoint that will be used to download result
files from completed jobs from that endpoint's plugin.  This sub-endpoint SHOULD accept a URI parameter used to specify
the type or name of the file that will be downloaded.

.*Example Plugin Definition*
[source, yaml]
----
  /example:
    post:
      body:
        application/json: lib.ExamplePluginRequest
      responses:
        200:
          body:
            application/json: lib.JobResponse
    /{file}:
      uriParameters:
        file:
          type: string
          description: MUST be one of "meta", "tabular", "statistics".
      post:
        body:
          application/json: lib.ExamplePluginRequest
        responses:
          200:
            body:
              text/plain: any
----


=== Plugin Context

On instantiation plugin implementations are provided a link:{kotlinPath}/plugins/PluginContext.kt[`PluginContext`]
instance which provides the following:

* Access to the plugin job's input data.
* Access to the plugin job's local filesystem workspace
* Method for starting/running arbitrary shell commands in the plugin job's context.

=== Input Data

On execution, plugins will be provided with the following values in addition to named tabular data files generated from
the `StreamSpec` list the plugin defines.

.*Standard Inputs*
--
* The original HTTP request sent in to trigger the execution of a job.
* The job configuration (pulled from and additionally available as part of the original HTTP request).
* Study metadata retrieved from the EDA Subsetting service.
--

=== Output Data

Plugins are expected to output specific target files which will be persisted to a cache in S3.

Plugins are not required to output every file listed below, but only the listed files will be persisted.

.*Expected Output Files*
--
`output-stats`::
Statistics data generated by the plugin execution.
+
This file will be made available for download via the HTTP API.

`output-meta`::
Metadata generated by the plugin execution.
+
This file will be made available for download via the HTTP API.

`output-data`::
Tabular data generated by the plugin execution.
+
This file will be made available for download via the HTTP API.

`error.log`::
`STDERR` output from the execution of a shell command via the Compute Service's CLI call API.
+
Plugins do not need to and should not write to this file directly, the `ComputeProcessBuilder` utility made available
through the provided plugin context will handle configuring external processes to write to this file.

`exception.log`::
Exception stacktrace output.  This file is created and populated with the stacktrace of uncaught exception thrown by a
plugin's execution.
+
Plugins may choose to write to this file if they handle their own exceptions internally and do not throw uncaught
exceptions.
--

=== Plugin Workspace

When executed, a plugin job will be provided with a temporary local scratch workspace.  Plugins are expected to write
their output data into this workspace from where it will be persisted to the S3 cache.

On completion of the plugin's execution, the workspace will be deleted.

Plugins may use this workspace for any additional filesystem based operations desired provided they do not extend beyond
the lifecycle of the source job itself.

== Project Development

=== Project Structure

This project is written in and divided into sections for two languages, Java and Kotlin.  The core of the service and
its internals are all written in Kotlin, and the segment of the project made for plugin writers is in Java.  The two
source sets exist under `src/main/java` and `src/main/kotlin`.

The intention here is a clear separation between service internals and plugin code that allows plugin developers to work
entirely in Java in a space free from service implementation clutter.

